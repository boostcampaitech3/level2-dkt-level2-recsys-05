{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MF를 이용한 간단한 변수 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "torch.set_printoptions(sci_mode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 간단한 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MakeDataset():\n",
    "\n",
    "    def __init__(self, DATA_PATH):\n",
    "        \n",
    "        dtype = {\n",
    "            'userID': 'int16',\n",
    "            'answerCode': 'int8',\n",
    "            'KnowledgeTag': 'int16'\n",
    "        }\n",
    "        \n",
    "        train_df = pd.read_csv(os.path.join(DATA_PATH, 'train_data.csv'), dtype=dtype, parse_dates=['Timestamp'])\n",
    "        train_df = train_df.sort_values(by=['userID', 'Timestamp']).reset_index(drop=True)\n",
    "        test_df = pd.read_csv(os.path.join(DATA_PATH, 'test_data.csv'), dtype=dtype, parse_dates=['Timestamp'])\n",
    "\n",
    "        def get_paper_number(x):\n",
    "            return x[1:-3]\n",
    "\n",
    "        def get_paper_question_number(x):\n",
    "            return x[-3:]\n",
    "\n",
    "        def get_large_paper_number(x):\n",
    "            return x[1:4]\n",
    "        \n",
    "        train_df['paper_number'] = train_df['assessmentItemID'].apply(lambda x : get_paper_number(x))\n",
    "        train_df['paper_question_number'] = train_df['assessmentItemID'].apply(lambda x : get_paper_question_number(x))\n",
    "        train_df['large_paper_number'] = train_df['assessmentItemID'].apply(lambda x : get_large_paper_number(x))\n",
    "\n",
    "        test_df['paper_number'] = test_df['assessmentItemID'].apply(lambda x : get_paper_number(x))\n",
    "        test_df['paper_question_number'] = test_df['assessmentItemID'].apply(lambda x : get_paper_question_number(x))\n",
    "        test_df['large_paper_number'] = test_df['assessmentItemID'].apply(lambda x : get_large_paper_number(x))\n",
    "\n",
    "        total_user_list = train_df['userID'].unique().tolist()\n",
    "\n",
    "        random.seed(22)\n",
    "        val_user_list = random.sample(total_user_list, test_df['userID'].nunique())\n",
    "\n",
    "        train = []\n",
    "        valid = []\n",
    "        test = []\n",
    "\n",
    "        group_df = train_df.groupby('userID')\n",
    "\n",
    "        for userID, df in group_df:\n",
    "            if userID in val_user_list:\n",
    "                trn_df = df.iloc[:-1, :]\n",
    "                val_df = df.iloc[-1:, :]\n",
    "\n",
    "                train.append(trn_df)\n",
    "                valid.append(val_df)\n",
    "            else:\n",
    "                train.append(df)\n",
    "\n",
    "        group_df = test_df.groupby('userID')\n",
    "\n",
    "        for userID, df in group_df:\n",
    "            trn_df = df.iloc[:-1, :]\n",
    "            te_df = df.iloc[-1:, :]\n",
    "\n",
    "            train.append(trn_df)\n",
    "            test.append(te_df)\n",
    "\n",
    "        train = pd.concat(train)\n",
    "        valid = pd.concat(valid)\n",
    "        test = pd.concat(test)\n",
    "\n",
    "        def get_val2idx(val_list : list) -> dict:\n",
    "            val2idx = {}\n",
    "            for idx, val in enumerate(val_list):\n",
    "                val2idx[val] = idx\n",
    "            \n",
    "            return val2idx\n",
    "\n",
    "        all_df = pd.concat([train, valid, test])\n",
    "\n",
    "        assessmentItemID2idx = get_val2idx(all_df['assessmentItemID'].unique().tolist())\n",
    "        testId2idx = get_val2idx(all_df['testId'].unique().tolist())\n",
    "        KnowledgeTag2idx = get_val2idx(all_df['KnowledgeTag'].unique().tolist())\n",
    "        large_paper_number2idx = get_val2idx(all_df['large_paper_number'].unique().tolist())\n",
    "\n",
    "        train['assessmentItemID2idx'] = train['assessmentItemID'].apply(lambda x : assessmentItemID2idx[x])\n",
    "        train['testId2idx'] = train['testId'].apply(lambda x : testId2idx[x])\n",
    "        train['KnowledgeTag2idx'] = train['KnowledgeTag'].apply(lambda x : KnowledgeTag2idx[x])\n",
    "        train['large_paper_number2idx'] = train['large_paper_number'].apply(lambda x : large_paper_number2idx[x])\n",
    "\n",
    "        valid['assessmentItemID2idx'] = valid['assessmentItemID'].apply(lambda x : assessmentItemID2idx[x])\n",
    "        valid['testId2idx'] = valid['testId'].apply(lambda x : testId2idx[x])\n",
    "        valid['KnowledgeTag2idx'] = valid['KnowledgeTag'].apply(lambda x : KnowledgeTag2idx[x])\n",
    "        valid['large_paper_number2idx'] = valid['large_paper_number'].apply(lambda x : large_paper_number2idx[x])\n",
    "\n",
    "        test['assessmentItemID2idx'] = test['assessmentItemID'].apply(lambda x : assessmentItemID2idx[x])\n",
    "        test['testId2idx'] = test['testId'].apply(lambda x : testId2idx[x])\n",
    "        test['KnowledgeTag2idx'] = test['KnowledgeTag'].apply(lambda x : KnowledgeTag2idx[x])\n",
    "        test['large_paper_number2idx'] = test['large_paper_number'].apply(lambda x : large_paper_number2idx[x])\n",
    "\n",
    "        self.train, self.valid, self.test = train, valid, test\n",
    "        self.num_userID = train['userID'].nunique()\n",
    "        self.num_assessmentItemID = len(assessmentItemID2idx)\n",
    "        self.num_testId = len(testId2idx)\n",
    "        self.num_KnowledgeTag = len(KnowledgeTag2idx)\n",
    "        self.num_large_paper_number = len(large_paper_number2idx)\n",
    "    \n",
    "    def get_data(self):\n",
    "        return self.train, self.valid, self.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, test = False):\n",
    "        self.userID = df['userID'].tolist()\n",
    "        self.assessmentItemID = df['assessmentItemID2idx'].tolist()\n",
    "        self.testId = df['testId2idx'].tolist()\n",
    "        self.KnowledgeTag = df['KnowledgeTag2idx'].tolist()\n",
    "        self.large_paper_number = df['large_paper_number2idx'].tolist()\n",
    "        self.test = test\n",
    "        if not self.test:\n",
    "            self.answerCode = df['answerCode'].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.userID)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        userID = self.userID[idx]\n",
    "        assessmentItemID = self.assessmentItemID[idx]\n",
    "        testId = self.testId[idx]\n",
    "        KnowledgeTag = self.KnowledgeTag[idx]\n",
    "        large_paper_number = self.large_paper_number[idx]\n",
    "        if not self.test:\n",
    "            answerCode = self.answerCode[idx]\n",
    "            return userID, assessmentItemID, testId, KnowledgeTag, large_paper_number, float(answerCode)\n",
    "        return userID, assessmentItemID, testId, KnowledgeTag, large_paper_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 간단한 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF(nn.Module):\n",
    "    def __init__(self, num_userID, num_assessmentItemID, num_testId, num_KnowledgeTag, num_large_paper_number, num_factor = 50, num_layers = 3, dropout_rate = 0.5):\n",
    "        super(MF, self).__init__()\n",
    "        self.userID_emb = nn.Embedding(num_userID, num_factor)\n",
    "        self.assessmentItemID_emb = nn.Embedding(num_assessmentItemID, num_factor)\n",
    "        self.testId_emb = nn.Embedding(num_testId, num_factor)\n",
    "        self.KnowledgeTag_emb = nn.Embedding(num_KnowledgeTag, num_factor)\n",
    "        self.large_paper_number_emb = nn.Embedding(num_large_paper_number, num_factor)\n",
    "\n",
    "        MLP_modules = []\n",
    "        input_size = num_factor\n",
    "        for i in range(num_layers):\n",
    "            MLP_modules.append(nn.Dropout(p = dropout_rate))\n",
    "            MLP_modules.append(nn.Linear(input_size, input_size // 2))\n",
    "            MLP_modules.append(nn.ReLU())\n",
    "            input_size = input_size // 2\n",
    "\n",
    "        self.MLP_layers = nn.Sequential(*MLP_modules)\n",
    "\n",
    "        self.predict_layer = nn.Sequential(\n",
    "            nn.Linear(input_size, 1, bias = True),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self._init_weight_()\n",
    "\n",
    "    def _init_weight_(self):\n",
    "        self.userID_emb.weight.data.normal_(0, 1.0 / self.userID_emb.embedding_dim)\n",
    "        self.assessmentItemID_emb.weight.data.normal_(0, 1.0 / self.assessmentItemID_emb.embedding_dim)\n",
    "        self.testId_emb.weight.data.normal_(0, 1.0 / self.testId_emb.embedding_dim)\n",
    "        self.KnowledgeTag_emb.weight.data.normal_(0, 1.0 / self.KnowledgeTag_emb.embedding_dim)\n",
    "        self.large_paper_number_emb.weight.data.normal_(0, 1.0 / self.large_paper_number_emb.embedding_dim)\n",
    "        \n",
    "        for m in self.MLP_layers:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "        \n",
    "        for m in self.predict_layer:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_uniform_(m.weight, a=1)\n",
    "    \n",
    "    def forward(self, userID, assessmentItemID, testId, KnowledgeTag, large_paper_number):\n",
    "        \n",
    "        userID_emb = self.userID_emb(userID)\n",
    "        assessmentItemID_emb = self.assessmentItemID_emb(assessmentItemID)\n",
    "        testId_emb = self.testId_emb(testId)\n",
    "        KnowledgeTag_emb = self.KnowledgeTag_emb(KnowledgeTag)\n",
    "        large_paper_number_emb = self.large_paper_number_emb(large_paper_number)\n",
    "\n",
    "        emb = userID_emb + assessmentItemID_emb + testId_emb + KnowledgeTag_emb + large_paper_number_emb\n",
    "\n",
    "        output = self.MLP_layers(emb)\n",
    "        output = self.predict_layer(output)\n",
    "\n",
    "        return output.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def train(model, data_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    loss_val = 0\n",
    "\n",
    "    for userID, assessmentItemID, testId, KnowledgeTag, large_paper_number, answerCode in data_loader:\n",
    "        userID, assessmentItemID, testId, KnowledgeTag, large_paper_number, answerCode = userID.to(device), assessmentItemID.to(device), testId.to(device), KnowledgeTag.to(device), large_paper_number.to(device), answerCode.type(torch.float32).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(userID, assessmentItemID, testId, KnowledgeTag, large_paper_number)\n",
    "        loss = criterion(output, answerCode)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_val += loss.item()\n",
    "\n",
    "    loss_val /= len(data_loader)\n",
    "\n",
    "    return loss_val\n",
    "\n",
    "def evaluate(model, data_loader):\n",
    "    model.eval()\n",
    "\n",
    "    target = []\n",
    "    pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for userID, assessmentItemID, testId, KnowledgeTag, large_paper_number, answerCode in data_loader:\n",
    "\n",
    "            userID, assessmentItemID, testId, KnowledgeTag, large_paper_number, answerCode = userID.to(device), assessmentItemID.to(device), testId.to(device), KnowledgeTag.to(device), large_paper_number.to(device), answerCode.type(torch.float32).to(device)\n",
    "\n",
    "            output = model(userID, assessmentItemID, testId, KnowledgeTag, large_paper_number)\n",
    "\n",
    "            target.extend(answerCode.cpu().numpy().tolist())\n",
    "            pred.extend(output.cpu().numpy().tolist())\n",
    "\n",
    "    roc_auc = roc_auc_score(target, pred)\n",
    "\n",
    "    return roc_auc\n",
    "\n",
    "\n",
    "def predict(model, data_loader):\n",
    "    model.eval()\n",
    "\n",
    "    pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for userID, assessmentItemID, testId, KnowledgeTag, large_paper_number in data_loader:\n",
    "\n",
    "            userID, assessmentItemID, testId, KnowledgeTag, large_paper_number = userID.to(device), assessmentItemID.to(device), testId.to(device), KnowledgeTag.to(device), large_paper_number.to(device)\n",
    "\n",
    "            output = model(userID, assessmentItemID, testId, KnowledgeTag, large_paper_number)\n",
    "\n",
    "            pred.extend(output.cpu().numpy().tolist())\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5000\n",
    "epochs = 20\n",
    "lr = 0.001\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "DATA_PATH = '/opt/ml/input/data'\n",
    "MODEL_PATH = '/opt/ml/model'\n",
    "SUBMISSION_PATH = '/opt/ml/submission'\n",
    "\n",
    "model_name = 'MF-base.pt'\n",
    "submission_name = 'baseline-MF.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(MODEL_PATH):\n",
    "    os.mkdir(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(SUBMISSION_PATH):\n",
    "    os.mkdir(SUBMISSION_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_dataset = MakeDataset(DATA_PATH = DATA_PATH)\n",
    "train_df, valid_df, test_df = make_dataset.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "seed_everything(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(df = train_df)\n",
    "train_data_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size = batch_size, \n",
    "    shuffle = True, \n",
    "    drop_last = False)\n",
    "\n",
    "valid_dataset = CustomDataset(df = valid_df)\n",
    "valid_data_loader = DataLoader(\n",
    "    valid_dataset, \n",
    "    batch_size = batch_size, \n",
    "    shuffle = False, \n",
    "    drop_last = False)\n",
    "\n",
    "\n",
    "test_dataset = CustomDataset(df = test_df, test = True)\n",
    "test_data_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size = batch_size, \n",
    "    shuffle = False, \n",
    "    drop_last = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MF(\n",
    "    num_userID = make_dataset.num_userID, \n",
    "    num_assessmentItemID = make_dataset.num_assessmentItemID, \n",
    "    num_testId = make_dataset.num_testId, \n",
    "    num_KnowledgeTag = make_dataset.num_KnowledgeTag, \n",
    "    num_large_paper_number = make_dataset.num_large_paper_number,).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_roc_auc = 0\n",
    "for epoch in range(1, epochs + 1):\n",
    "    tbar = tqdm(range(1))\n",
    "    for _ in tbar:\n",
    "        train_loss = train(model = model, data_loader = train_data_loader, criterion = criterion, optimizer = optimizer)\n",
    "        roc_auc = evaluate(model = model, data_loader = valid_data_loader)\n",
    "        if best_roc_auc < roc_auc:\n",
    "            best_roc_auc = roc_auc\n",
    "            torch.save(model.state_dict(), os.path.join(MODEL_PATH, model_name))\n",
    "\n",
    "        tbar.set_description(f'Epoch: {epoch:3d}| Train loss: {train_loss:.5f}| roc_auc: {roc_auc:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MF(\n",
    "    num_userID = make_dataset.num_userID, \n",
    "    num_assessmentItemID = make_dataset.num_assessmentItemID, \n",
    "    num_testId = make_dataset.num_testId, \n",
    "    num_KnowledgeTag = make_dataset.num_KnowledgeTag, \n",
    "    num_large_paper_number = make_dataset.num_large_paper_number,).to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(os.path.join(MODEL_PATH, model_name)))\n",
    "pred_list = predict(model = model, data_loader = test_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(data = np.array(pred_list), columns = ['prediction'])\n",
    "submission['id'] = submission.index\n",
    "submission = submission[['id', 'prediction']]\n",
    "submission.to_csv(os.path.join(SUBMISSION_PATH, submission_name), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
